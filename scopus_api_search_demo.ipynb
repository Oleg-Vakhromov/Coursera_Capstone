{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ffd729-72a3-4184-809a-6caa52d00789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last update October 6, 2024 18:27\n",
    "\n",
    "from elsapy.elsclient import ElsClient\n",
    "from elsapy.elsprofile import ElsAuthor, ElsAffil\n",
    "from elsapy.elsdoc import FullDoc, AbsDoc\n",
    "from elsapy.elssearch import ElsSearch\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "import json\n",
    "import requests\n",
    "    \n",
    "## Load configuration\n",
    "con_file = open(\"config.json\")\n",
    "config = json.load(con_file)\n",
    "con_file.close()\n",
    "\n",
    "## Initialize client\n",
    "client = ElsClient(config['apikey'])\n",
    "client.inst_token = config['insttoken']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a584eb2-d65b-4bbf-adf9-02b29cf52f71",
   "metadata": {},
   "source": [
    "<h4>Helper functions</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af316ee3-1aa0-435a-8f57-2976efb35807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize variables and dataframes\n",
    "scopus_stats_raw = pd.DataFrame(columns=['EID', 'Scopus ID', 'Cited by', 'Authors', 'Number of authors', \n",
    "                                         'Title', 'Year', 'Source title', 'Number of author keywords', \n",
    "                                         'Abstract', 'Number of references'])\n",
    "\n",
    "references = []\n",
    "\n",
    "# Compile a dataframe of referenced papers\n",
    "# 'Cited by' - Scopus ID of a referencing paper\n",
    "# 'Paper' - Scopus ID of a referenced paper\n",
    "# 'Title' - Title of the referenced paper\n",
    "# 'Year' - Publication year of the referenced paper\n",
    "\n",
    "citation_df = pd.DataFrame(columns=['Cited by','Paper', 'Title','Year'])\n",
    "\n",
    "not_in_db =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1b38a8-3e22-408f-b022-6023890fe6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions to retrieve metadata for papers on the eid_list\n",
    "\n",
    "def scopus_search(search_query):\n",
    "    doc_srch = ElsSearch(search_query,'scopus')\n",
    "    doc_srch.execute(client, get_all = True)\n",
    "    search_df = pd.DataFrame(doc_srch.results)\n",
    "    print (\"Search returned \", len(doc_srch.results), \"results.\")\n",
    "    return search_df\n",
    "\n",
    "def fetch_abstract(paper_id):\n",
    "    # Set the base URL with a placeholder for the Scopus ID\n",
    "\n",
    "    if paper_id[0:7] == \"2-s2.0-\":\n",
    "        eid\n",
    "    else:\n",
    "        eid = \"2-s2.0-\" + paper_id\n",
    "        \n",
    "    url = f\"https://api.elsevier.com/content/abstract/eid/{eid}\"\n",
    "\n",
    "    # Set the query parameters\n",
    "    params = {\n",
    "        # Substitute X's with your personal Scopus API key\n",
    "        'apiKey': 'XXXXXXXXXXXXX',\n",
    "        'insttoken': 'XXXXXXXXXXXXX'\n",
    "    }\n",
    "\n",
    "    # Set the headers\n",
    "    headers = {\n",
    "        'Accept': 'application/json'\n",
    "    }\n",
    "\n",
    "    # Make the GET request\n",
    "    response = requests.get(url, headers=headers, params=params)\n",
    "\n",
    "    # Check the status code of the response\n",
    "    if response.status_code == 200:\n",
    "        # Return the JSON content of the response\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Failed to fetch data. Status code: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "def extract_references(json_data):\n",
    "    # Navigate to the 'item.bibrecord.tail.bibliography.reference' key\n",
    "    try:\n",
    "        references = json_data['abstracts-retrieval-response']['item']['bibrecord']['tail']['bibliography']['reference']\n",
    "        # Convert the references to a DataFrame\n",
    "        df = pd.json_normalize(references)\n",
    "        return df\n",
    "    except KeyError as e:\n",
    "        print(f\"Key not found: {e}\")\n",
    "        return None\n",
    "\n",
    "def extract_metadata(data):\n",
    "\n",
    "    # Number of authors\n",
    "    num_authors = len(data['abstracts-retrieval-response']['item']['bibrecord']['head']['author-group'])\n",
    "    # print(num_authors)\n",
    "\n",
    "    # Names of authors\n",
    "\n",
    "    authors = ''\n",
    "    \n",
    "\n",
    "    try:\n",
    "        for author in data['abstracts-retrieval-response']['item']['bibrecord']['head']['author-group']:\n",
    "            authors += author['author'][0]['ce:indexed-name'] + \"; \"\n",
    "        authors = authors[:-2]\n",
    "    except:\n",
    "        authors += data['abstracts-retrieval-response']['item']['bibrecord']['head']['author-group']['author'][0]['ce:indexed-name']\n",
    "        num_authors = 1\n",
    "    # print(authors)\n",
    "    \n",
    "    # Title of the paper\n",
    "    title = data['abstracts-retrieval-response']['item']['bibrecord']['head']['citation-title']\n",
    "    # print(title)\n",
    "\n",
    "    # Author keywords\n",
    "    try:\n",
    "        num_auth_keywords = len(data['abstracts-retrieval-response']['item']['bibrecord']['head']['citation-info']['author-keywords']['author-keyword'])\n",
    "    except:\n",
    "        num_auth_keywords = 0\n",
    "    # print(num_auth_keywords)\n",
    "\n",
    "    # Abstract\n",
    "    abstract = data['abstracts-retrieval-response']['item']['bibrecord']['head']['abstracts']\n",
    "    # print(abstract)\n",
    "    \n",
    "    # Source title - name of the journal\n",
    "    source = data['abstracts-retrieval-response']['item']['bibrecord']['head']['source']['sourcetitle']\n",
    "    # print(source)\n",
    "\n",
    "    # Year of publication\n",
    "    year = int(data['abstracts-retrieval-response']['item']['bibrecord']['head']['source']['publicationdate']['year'])\n",
    "    # print(year)\n",
    "\n",
    "    # Number of references used in the paper\n",
    "    num_ref = int(data['abstracts-retrieval-response']['item']['bibrecord']['tail']['bibliography']['@refcount'])\n",
    "    # print(num_ref)\n",
    "\n",
    "    # Extract references\n",
    "    references_df = extract_references(data)\n",
    "    # print('ref_df')\n",
    "    \n",
    "    return [authors, num_authors, title, year, source, num_auth_keywords, abstract, num_ref , references_df]\n",
    "\n",
    "\n",
    "def add_papers(scopus_ids):\n",
    "\n",
    "    scopus_stats_raw = pd.DataFrame(columns=['EID', 'Scopus ID', 'Cited by', 'Authors', 'Number of authors', \n",
    "                                         'Title', 'Year', 'Source title', 'Number of author keywords', \n",
    "                                         'Abstract', 'Number of references'])\n",
    "\n",
    "    # Turn scopus ids into a search query \n",
    "    prefix = 'EID(\"2-s2.0-'\n",
    "    suffix = '\") OR '\n",
    "    search_query =''\n",
    "\n",
    "    print(r'Received {} IDs to search'.format(len(scopus_ids)))\n",
    "         \n",
    "    for id in scopus_ids:\n",
    "        search_query += prefix + str(id) + suffix\n",
    "    search_query = search_query[:-4]\n",
    "\n",
    "    search_df = scopus_search(search_query)\n",
    "\n",
    "    num_papers = len(search_df)\n",
    "    # num_papers = 4 # Limiting the number of papers for testing purposes\n",
    "\n",
    "    for paper in range(num_papers):\n",
    "        eid = search_df.loc[paper, 'eid']\n",
    "        scopus_id = search_df.loc[paper, 'dc:identifier'].replace(\"SCOPUS_ID:\",\"\")\n",
    "        cited_count = search_df.loc[paper,'citedby-count']\n",
    "        try:\n",
    "            data = fetch_abstract(scopus_id)\n",
    "            metadata = extract_metadata(data)\n",
    "            record_item = [eid, scopus_id, cited_count] + metadata[:-1]\n",
    "            scopus_stats_raw.loc[len(scopus_stats_raw)]=record_item\n",
    "            references.append([scopus_id, metadata[-1]])\n",
    "        except:\n",
    "            print('Could not fetch data for Scopus ID: ', scopus_id)\n",
    "        \n",
    "    \n",
    "    scopus_add = scopus_stats_raw[['Authors', 'Title', 'EID', 'Scopus ID','Year',\n",
    "           'Source title', 'Abstract','Cited by', 'Number of author keywords',\n",
    "           'Number of authors', 'Number of references']]  \n",
    "\n",
    "    return scopus_add"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc56707d-f8a2-4fb1-9b49-fc7a56d33cbd",
   "metadata": {},
   "source": [
    "<h4>Start here</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178ef540-80a4-45c4-9b23-e58cbb75faaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conduct search of the Scopus database\n",
    "\n",
    "search_query = '( TITLE-ABS-KEY ( retail AND investor* ) AND TITLE-ABS-KEY ( \"meme stock*\" OR \"social media\" OR \"gamestop\" OR \"robinhood\" OR \"roaring kitty\" OR \"reddit\" OR \"4chan\" OR \"wallstreetbets\" OR \"disinformation\" OR \"viral\" OR \"influencer*\" OR \"manipulation\" OR \"sentiment\" OR \"activism\" OR \"facebook\" OR \"twitter\" OR \"stocktwits\" OR \"pump and dump\" ) ) AND ( LIMIT-TO ( DOCTYPE , \"ar\" ) ) AND ( LIMIT-TO ( SUBJAREA , \"ECON\" ) OR LIMIT-TO ( SUBJAREA , \"BUSI\" ) OR LIMIT-TO ( SUBJAREA , \"SOCI\" ) OR LIMIT-TO ( SUBJAREA , \"PSYC\" ) OR LIMIT-TO ( SUBJAREA , \"MULT\" ) OR LIMIT-TO ( SUBJAREA , \"COMP\" ) OR LIMIT-TO ( SUBJAREA , \"ARTS\" ) ) AND ( LIMIT-TO ( LANGUAGE , \"English\" ) )'\n",
    "\n",
    "search_df = scopus_search(search_query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142d0828-bf3a-4ce1-8431-49399eb0fe48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go from paper to paper and pull relevant metadata\n",
    "\n",
    "num_papers = len(search_df)\n",
    "# num_papers = 4 # Limiting the number of papers for testing purposes\n",
    "\n",
    "for paper in range(num_papers):\n",
    "    eid = search_df.loc[paper, 'eid']\n",
    "    scopus_id = search_df.loc[paper, 'dc:identifier'].replace(\"SCOPUS_ID:\",\"\")\n",
    "    cited_count = search_df.loc[paper,'citedby-count']\n",
    "    try:\n",
    "        data = fetch_abstract(scopus_id)\n",
    "        metadata = extract_metadata(data)\n",
    "        record_item = [eid, scopus_id, cited_count] + metadata[:-1]\n",
    "        scopus_stats_raw.loc[len(scopus_stats_raw)]=record_item\n",
    "        references.append([scopus_id, metadata[-1]])\n",
    "    except:\n",
    "        print('Could not fetch data for Scopus ID: ', scopus_id)\n",
    "    \n",
    "\n",
    "scopus_stats = scopus_stats_raw[['Authors', 'Title', 'EID', 'Scopus ID','Year',\n",
    "       'Source title', 'Abstract','Cited by', 'Number of author keywords',\n",
    "       'Number of authors', 'Number of references']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ebf078-6558-43a3-ab07-6ca7c1e8db26",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_error = []\n",
    "for ref_paper in references:\n",
    "    cited_by = ref_paper[0]\n",
    "    num_refs = len(ref_paper[1])\n",
    "    for ref in range(num_refs):\n",
    "        try:\n",
    "            # paper = ref_paper[1].loc[ref,'ref-info.refd-itemidlist.itemid'][1]['$']\n",
    "            for id in ref_paper[1].loc[ref, 'ref-info.refd-itemidlist.itemid']:\n",
    "                if id['@idtype'] == 'SGR':\n",
    "                    paper = id['$']\n",
    "                else:\n",
    "                    pass\n",
    "            title = ref_paper[1].loc[ref, 'ref-info.ref-title.ref-titletext']\n",
    "            year = ref_paper[1].loc[ref, 'ref-info.ref-publicationyear.@first']\n",
    "            citation_df.loc[len(citation_df)] = [cited_by, paper, title, year]\n",
    "        except:\n",
    "            paper = ref_paper[1].loc[ref,'ref-info.refd-itemidlist.itemid.$']\n",
    "            # for id in ref_paper[1].loc[ref, 'ref-info.refd-itemidlist.itemid.$']:\n",
    "            #     if id['@idtype'] == 'SGR':\n",
    "            #         paper = id['$']\n",
    "            #     else:\n",
    "            #         pass\n",
    "            try:\n",
    "                title = ref_paper[1].loc[ref, 'ref-info.ref-title.ref-titletext']\n",
    "            except:\n",
    "                title = ref_paper[1].loc[ref, 'ref-info.ref-sourcetitle']\n",
    "            year = ref_paper[1].loc[ref, 'ref-info.ref-publicationyear.@first']\n",
    "            citation_df.loc[len(citation_df)] = [cited_by, paper, title, year]\n",
    "\n",
    "        if str(paper) == 'CR1':\n",
    "            ref_error.append(ref_paper[1].loc[ref,:])\n",
    "            print('gotcha')\n",
    "                            \n",
    "\n",
    "\n",
    "citation_df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe48eb81-42a0-4713-9f46-9932621f8b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_citations_df = citation_df.groupby('Paper')['Cited by'].count().to_frame().sort_values(by='Cited by', ascending=False)\n",
    "\n",
    "# Criteria for inclusion in  local citations\n",
    "\n",
    "min_num_citations = local_citations_df.describe([0.995]).loc['99.5%','Cited by']\n",
    "if min_num_citations > 3:\n",
    "    pass\n",
    "else:\n",
    "    min_num_citations = 3\n",
    "\n",
    "print(r'Using {} as minimum number of citations'.format(min_num_citations))\n",
    "LCT = local_citations_df[local_citations_df['Cited by'] >= min_num_citations].reset_index()\n",
    "# citation_df.merge(LCT.set_index('Paper'), on='Paper', how='outer', suffixes=('', '_local'))\n",
    "print(r'Number of papers: {}'.format(len(LCT)))\n",
    "LCT.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e14678-cbf4-4e2c-81b8-e200bd3d8cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify papers that are currently not in the database\n",
    "not_in_db = []\n",
    "\n",
    "for i in range(len(LCT)):\n",
    "    scopus_id = str(LCT.loc[i,'Paper'])\n",
    "    if scopus_id in list(scopus_stats['Scopus ID']):\n",
    "        pass\n",
    "    else:\n",
    "        not_in_db.append(scopus_id)\n",
    "print(r'There is a total of {} papers which were previously not included in the database'.format(len(not_in_db)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5705fe-17e5-4e08-bfda-cc0c5fe1da85",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = add_papers(not_in_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e11a1a-ae91-4bdb-9228-7843444d4794",
   "metadata": {},
   "outputs": [],
   "source": [
    "scopus_stats = pd.concat([scopus_stats, df], ignore_index=True)\n",
    "scopus_stats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3b0d91-0099-4d16-9d83-18903b2693b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "scopus_stats.to_csv('scopus_stats.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a60787e-f19f-4c00-bf65-2877a4b74417",
   "metadata": {},
   "outputs": [],
   "source": [
    "citation_df.to_csv('citation_df.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
